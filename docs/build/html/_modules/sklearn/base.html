<!doctype html>
<html class="no-js" lang="en" data-content_root="../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2024.01.29 -->
        <title>sklearn.base - step-select</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">step-select</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">step-select</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html#step-select">step-select</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../modules.html">steps</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of steps</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../steps.html">steps package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/chris-santiago/steps">Github Repo</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for sklearn.base</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Base classes for all estimators.&quot;&quot;&quot;</span>

<span class="c1"># Author: Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">platform</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">__version__</span>
<span class="kn">from</span> <span class="nn">._config</span> <span class="kn">import</span> <span class="n">config_context</span><span class="p">,</span> <span class="n">get_config</span>
<span class="kn">from</span> <span class="nn">.exceptions</span> <span class="kn">import</span> <span class="n">InconsistentVersionWarning</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">_IS_32BIT</span>
<span class="kn">from</span> <span class="nn">.utils._estimator_html_repr</span> <span class="kn">import</span> <span class="n">_HTMLDocumentationLinkMixin</span><span class="p">,</span> <span class="n">estimator_html_repr</span>
<span class="kn">from</span> <span class="nn">.utils._metadata_requests</span> <span class="kn">import</span> <span class="n">_MetadataRequester</span><span class="p">,</span> <span class="n">_routing_enabled</span>
<span class="kn">from</span> <span class="nn">.utils._param_validation</span> <span class="kn">import</span> <span class="n">validate_parameter_constraints</span>
<span class="kn">from</span> <span class="nn">.utils._set_output</span> <span class="kn">import</span> <span class="n">_SetOutputMixin</span>
<span class="kn">from</span> <span class="nn">.utils._tags</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_DEFAULT_TAGS</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_feature_names_in</span><span class="p">,</span>
    <span class="n">_check_y</span><span class="p">,</span>
    <span class="n">_generate_get_feature_names_out</span><span class="p">,</span>
    <span class="n">_get_feature_names</span><span class="p">,</span>
    <span class="n">_is_fitted</span><span class="p">,</span>
    <span class="n">_num_features</span><span class="p">,</span>
    <span class="n">check_array</span><span class="p">,</span>
    <span class="n">check_is_fitted</span><span class="p">,</span>
    <span class="n">check_X_y</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">clone</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct a new unfitted estimator with the same parameters.</span>

<span class="sd">    Clone does a deep copy of the model in an estimator</span>
<span class="sd">    without actually copying attached data. It returns a new estimator</span>
<span class="sd">    with the same parameters that has not been fitted on any data.</span>

<span class="sd">    .. versionchanged:: 1.3</span>
<span class="sd">        Delegates to `estimator.__sklearn_clone__` if the method exists.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : {list, tuple, set} of estimator instance or a single \</span>
<span class="sd">            estimator instance</span>
<span class="sd">        The estimator or group of estimators to be cloned.</span>
<span class="sd">    safe : bool, default=True</span>
<span class="sd">        If safe is False, clone will fall back to a deep copy on objects</span>
<span class="sd">        that are not estimators. Ignored if `estimator.__sklearn_clone__`</span>
<span class="sd">        exists.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    estimator : object</span>
<span class="sd">        The deep copy of the input, an estimator if input is an estimator.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    If the estimator&#39;s `random_state` parameter is an integer (or if the</span>
<span class="sd">    estimator doesn&#39;t have a `random_state` parameter), an *exact clone* is</span>
<span class="sd">    returned: the clone and the original estimator will give the exact same</span>
<span class="sd">    results. Otherwise, *statistical clone* is returned: the clone might</span>
<span class="sd">    return different results from the original estimator. More details can be</span>
<span class="sd">    found in :ref:`randomness`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import clone</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; X = [[-1, 0], [0, 1], [0, -1], [1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; y = [0, 0, 1, 1]</span>
<span class="sd">    &gt;&gt;&gt; classifier = LogisticRegression().fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; cloned_classifier = clone(classifier)</span>
<span class="sd">    &gt;&gt;&gt; hasattr(classifier, &quot;classes_&quot;)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; hasattr(cloned_classifier, &quot;classes_&quot;)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; classifier is cloned_classifier</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;__sklearn_clone__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isclass</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">estimator</span><span class="o">.</span><span class="n">__sklearn_clone__</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">_clone_parametrized</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_clone_parametrized</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Default implementation of clone. See :func:`sklearn.base.clone` for details.&quot;&quot;&quot;</span>

    <span class="n">estimator_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">estimator_type</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">estimator</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="n">estimator_type</span> <span class="ow">in</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">set</span><span class="p">,</span> <span class="nb">frozenset</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">estimator_type</span><span class="p">([</span><span class="n">clone</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="n">safe</span><span class="p">)</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">estimator</span><span class="p">])</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;get_params&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">safe</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot clone object. &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;You should provide an instance of &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;scikit-learn estimator instead of a class.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;Cannot clone object &#39;</span><span class="si">%s</span><span class="s2">&#39; (type </span><span class="si">%s</span><span class="s2">): &quot;</span>
                    <span class="s2">&quot;it does not seem to be a scikit-learn &quot;</span>
                    <span class="s2">&quot;estimator as it does not implement a &quot;</span>
                    <span class="s2">&quot;&#39;get_params&#39; method.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">estimator</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">))</span>
                <span class="p">)</span>

    <span class="n">klass</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="vm">__class__</span>
    <span class="n">new_object_params</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">new_object_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">new_object_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">safe</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">new_object</span> <span class="o">=</span> <span class="n">klass</span><span class="p">(</span><span class="o">**</span><span class="n">new_object_params</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">new_object</span><span class="o">.</span><span class="n">_metadata_request</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">estimator</span><span class="o">.</span><span class="n">_metadata_request</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="n">params_set</span> <span class="o">=</span> <span class="n">new_object</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># quick sanity check of the parameters of the clone</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">new_object_params</span><span class="p">:</span>
        <span class="n">param1</span> <span class="o">=</span> <span class="n">new_object_params</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">param2</span> <span class="o">=</span> <span class="n">params_set</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">param1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">param2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Cannot clone object </span><span class="si">%s</span><span class="s2">, as the constructor &quot;</span>
                <span class="s2">&quot;either does not set or modifies parameter </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="c1"># _sklearn_output_config is used by `set_output` to configure the output</span>
    <span class="c1"># container of an estimator.</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_sklearn_output_config&quot;</span><span class="p">):</span>
        <span class="n">new_object</span><span class="o">.</span><span class="n">_sklearn_output_config</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
            <span class="n">estimator</span><span class="o">.</span><span class="n">_sklearn_output_config</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">new_object</span>


<span class="k">class</span> <span class="nc">BaseEstimator</span><span class="p">(</span><span class="n">_HTMLDocumentationLinkMixin</span><span class="p">,</span> <span class="n">_MetadataRequester</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for all estimators in scikit-learn.</span>

<span class="sd">    Inheriting from this class provides default implementations of:</span>

<span class="sd">    - setting and getting parameters used by `GridSearchCV` and friends;</span>
<span class="sd">    - textual and HTML representation displayed in terminals and IDEs;</span>
<span class="sd">    - estimator serialization;</span>
<span class="sd">    - parameters validation;</span>
<span class="sd">    - data validation;</span>
<span class="sd">    - feature names validation.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`.</span>


<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    All estimators should specify all the parameters that can be set</span>
<span class="sd">    at the class level in their ``__init__`` as explicit keyword</span>
<span class="sd">    arguments (no ``*args`` or ``**kwargs``).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(BaseEstimator):</span>
<span class="sd">    ...     def __init__(self, *, param=1):</span>
<span class="sd">    ...         self.param = param</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.is_fitted_ = True</span>
<span class="sd">    ...         return self</span>
<span class="sd">    ...     def predict(self, X):</span>
<span class="sd">    ...         return np.full(shape=X.shape[0], fill_value=self.param)</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator(param=2)</span>
<span class="sd">    &gt;&gt;&gt; estimator.get_params()</span>
<span class="sd">    {&#39;param&#39;: 2}</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 0, 1])</span>
<span class="sd">    &gt;&gt;&gt; estimator.fit(X, y).predict(X)</span>
<span class="sd">    array([2, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; estimator.set_params(param=3).fit(X, y).predict(X)</span>
<span class="sd">    array([3, 3, 3])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_get_param_names</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get parameter names for the estimator&quot;&quot;&quot;</span>
        <span class="c1"># fetch the constructor or the original constructor before</span>
        <span class="c1"># deprecation wrapping if any</span>
        <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span> <span class="s2">&quot;deprecated_original&quot;</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__init__</span><span class="p">:</span>
            <span class="c1"># No explicit constructor to introspect</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># introspect the constructor arguments to find the model parameters</span>
        <span class="c1"># to represent</span>
        <span class="n">init_signature</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="c1"># Consider the constructor parameters excluding &#39;self&#39;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">p</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">init_signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;self&quot;</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_KEYWORD</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_POSITIONAL</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;scikit-learn estimators should always &quot;</span>
                    <span class="s2">&quot;specify their parameters in the signature&quot;</span>
                    <span class="s2">&quot; of their __init__ (no varargs).&quot;</span>
                    <span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> with constructor </span><span class="si">%s</span><span class="s2"> doesn&#39;t &quot;</span>
                    <span class="s2">&quot; follow this convention.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">init_signature</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="c1"># Extract and sort argument names excluding &#39;self&#39;</span>
        <span class="k">return</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">parameters</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get parameters for this estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        deep : bool, default=True</span>
<span class="sd">            If True, will return the parameters for this estimator and</span>
<span class="sd">            contained subobjects that are estimators.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        params : dict</span>
<span class="sd">            Parameter names mapped to their values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">():</span>
            <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">deep</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;get_params&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
                <span class="n">deep_items</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="n">out</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">deep_items</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the parameters of this estimator.</span>

<span class="sd">        The method works on simple estimators as well as on nested objects</span>
<span class="sd">        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have</span>
<span class="sd">        parameters of the form ``&lt;component&gt;__&lt;parameter&gt;`` so that it&#39;s</span>
<span class="sd">        possible to update each component of a nested object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        **params : dict</span>
<span class="sd">            Estimator parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : estimator instance</span>
<span class="sd">            Estimator instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># Simple optimization to gain speed (inspect is slow)</span>
            <span class="k">return</span> <span class="bp">self</span>
        <span class="n">valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">nested_params</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># grouped by prefix</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">key</span><span class="p">,</span> <span class="n">delim</span><span class="p">,</span> <span class="n">sub_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="s2">&quot;__&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_params</span><span class="p">:</span>
                <span class="n">local_valid_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_param_names</span><span class="p">()</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Invalid parameter </span><span class="si">{</span><span class="n">key</span><span class="si">!r}</span><span class="s2"> for estimator </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Valid parameters are: </span><span class="si">{</span><span class="n">local_valid_params</span><span class="si">!r}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">delim</span><span class="p">:</span>
                <span class="n">nested_params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">sub_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">sub_params</span> <span class="ow">in</span> <span class="n">nested_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">valid_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">sub_params</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__sklearn_clone__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_clone_parametrized</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N_CHAR_MAX</span><span class="o">=</span><span class="mi">700</span><span class="p">):</span>
        <span class="c1"># N_CHAR_MAX is the (approximate) maximum number of non-blank</span>
        <span class="c1"># characters to render. We pass it as an optional parameter to ease</span>
        <span class="c1"># the tests.</span>

        <span class="kn">from</span> <span class="nn">.utils._pprint</span> <span class="kn">import</span> <span class="n">_EstimatorPrettyPrinter</span>

        <span class="n">N_MAX_ELEMENTS_TO_SHOW</span> <span class="o">=</span> <span class="mi">30</span>  <span class="c1"># number of elements to show in sequences</span>

        <span class="c1"># use ellipsis for sequences with a lot of elements</span>
        <span class="n">pp</span> <span class="o">=</span> <span class="n">_EstimatorPrettyPrinter</span><span class="p">(</span>
            <span class="n">compact</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">indent</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">indent_at_name</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">n_max_elements_to_show</span><span class="o">=</span><span class="n">N_MAX_ELEMENTS_TO_SHOW</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">repr_</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">pformat</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Use bruteforce ellipsis when there are a lot of non-blank characters</span>
        <span class="n">n_nonblank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">repr_</span><span class="o">.</span><span class="n">split</span><span class="p">()))</span>
        <span class="k">if</span> <span class="n">n_nonblank</span> <span class="o">&gt;</span> <span class="n">N_CHAR_MAX</span><span class="p">:</span>
            <span class="n">lim</span> <span class="o">=</span> <span class="n">N_CHAR_MAX</span> <span class="o">//</span> <span class="mi">2</span>  <span class="c1"># apprx number of chars to keep on both ends</span>
            <span class="n">regex</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;^(\s*\S){</span><span class="si">%d</span><span class="s2">}&quot;</span> <span class="o">%</span> <span class="n">lim</span>
            <span class="c1"># The regex &#39;^(\s*\S){%d}&#39; % n</span>
            <span class="c1"># matches from the start of the string until the nth non-blank</span>
            <span class="c1"># character:</span>
            <span class="c1"># - ^ matches the start of string</span>
            <span class="c1"># - (pattern){n} matches n repetitions of pattern</span>
            <span class="c1"># - \s*\S matches a non-blank char following zero or more blanks</span>
            <span class="n">left_lim</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">regex</span><span class="p">,</span> <span class="n">repr_</span><span class="p">)</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>
            <span class="n">right_lim</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">regex</span><span class="p">,</span> <span class="n">repr_</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

            <span class="k">if</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="ow">in</span> <span class="n">repr_</span><span class="p">[</span><span class="n">left_lim</span><span class="p">:</span><span class="o">-</span><span class="n">right_lim</span><span class="p">]:</span>
                <span class="c1"># The left side and right side aren&#39;t on the same line.</span>
                <span class="c1"># To avoid weird cuts, e.g.:</span>
                <span class="c1"># categoric...ore&#39;,</span>
                <span class="c1"># we need to start the right side with an appropriate newline</span>
                <span class="c1"># character so that it renders properly as:</span>
                <span class="c1"># categoric...</span>
                <span class="c1"># handle_unknown=&#39;ignore&#39;,</span>
                <span class="c1"># so we add [^\n]*\n which matches until the next \n</span>
                <span class="n">regex</span> <span class="o">+=</span> <span class="sa">r</span><span class="s2">&quot;[^\n]*\n&quot;</span>
                <span class="n">right_lim</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">regex</span><span class="p">,</span> <span class="n">repr_</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>

            <span class="n">ellipsis</span> <span class="o">=</span> <span class="s2">&quot;...&quot;</span>
            <span class="k">if</span> <span class="n">left_lim</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">ellipsis</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">repr_</span><span class="p">)</span> <span class="o">-</span> <span class="n">right_lim</span><span class="p">:</span>
                <span class="c1"># Only add ellipsis if it results in a shorter repr</span>
                <span class="n">repr_</span> <span class="o">=</span> <span class="n">repr_</span><span class="p">[:</span><span class="n">left_lim</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;...&quot;</span> <span class="o">+</span> <span class="n">repr_</span><span class="p">[</span><span class="o">-</span><span class="n">right_lim</span><span class="p">:]</span>

        <span class="k">return</span> <span class="n">repr_</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;__slots__&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;You cannot use `__slots__` in objects inheriting from &quot;</span>
                <span class="s2">&quot;`sklearn.base.BaseEstimator`.&quot;</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">state</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__getstate__</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># For Python 3.11+, empty instance (no `__slots__`,</span>
                <span class="c1"># and `__dict__`) will return a state equal to `None`.</span>
                <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="c1"># Python &lt; 3.11</span>
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__module__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;sklearn.&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">_sklearn_version</span><span class="o">=</span><span class="n">__version__</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__module__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;sklearn.&quot;</span><span class="p">):</span>
            <span class="n">pickle_version</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_sklearn_version&quot;</span><span class="p">,</span> <span class="s2">&quot;pre-0.18&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">pickle_version</span> <span class="o">!=</span> <span class="n">__version__</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="n">InconsistentVersionWarning</span><span class="p">(</span>
                        <span class="n">estimator_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                        <span class="n">current_sklearn_version</span><span class="o">=</span><span class="n">__version__</span><span class="p">,</span>
                        <span class="n">original_sklearn_version</span><span class="o">=</span><span class="n">pickle_version</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_DEFAULT_TAGS</span>

    <span class="k">def</span> <span class="nf">_get_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">collected_tags</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">base_class</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getmro</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">base_class</span><span class="p">,</span> <span class="s2">&quot;_more_tags&quot;</span><span class="p">):</span>
                <span class="c1"># need the if because mixins might not have _more_tags</span>
                <span class="c1"># but might do redundant work in estimators</span>
                <span class="c1"># (i.e. calling more tags on BaseEstimator multiple times)</span>
                <span class="n">more_tags</span> <span class="o">=</span> <span class="n">base_class</span><span class="o">.</span><span class="n">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="n">collected_tags</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">more_tags</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">collected_tags</span>

    <span class="k">def</span> <span class="nf">_check_n_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the `n_features_in_` attribute, or check against it.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            The input samples.</span>
<span class="sd">        reset : bool</span>
<span class="sd">            If True, the `n_features_in_` attribute is set to `X.shape[1]`.</span>
<span class="sd">            If False and the attribute exists, then check that it is equal to</span>
<span class="sd">            `X.shape[1]`. If False and the attribute does *not* exist, then</span>
<span class="sd">            the check is skipped.</span>
<span class="sd">            .. note::</span>
<span class="sd">               It is recommended to call reset=True in `fit` and in the first</span>
<span class="sd">               call to `partial_fit`. All other methods that validate `X`</span>
<span class="sd">               should set `reset=False`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">n_features</span> <span class="o">=</span> <span class="n">_num_features</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">reset</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;n_features_in_&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;X does not contain any features, but &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> is expecting &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="si">}</span><span class="s2"> features&quot;</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="c1"># If the number of features is not defined and reset=True,</span>
            <span class="c1"># then we skip this check</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span> <span class="o">=</span> <span class="n">n_features</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;n_features_in_&quot;</span><span class="p">):</span>
            <span class="c1"># Skip this check if the expected number of expected input features</span>
            <span class="c1"># was not recorded by calling fit first. This is typically the case</span>
            <span class="c1"># for stateless transformers.</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">n_features</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;X has </span><span class="si">{</span><span class="n">n_features</span><span class="si">}</span><span class="s2"> features, but </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;is expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_features_in_</span><span class="si">}</span><span class="s2"> features as input.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_feature_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">reset</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set or check the `feature_names_in_` attribute.</span>

<span class="sd">        .. versionadded:: 1.0</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {ndarray, dataframe} of shape (n_samples, n_features)</span>
<span class="sd">            The input samples.</span>

<span class="sd">        reset : bool</span>
<span class="sd">            Whether to reset the `feature_names_in_` attribute.</span>
<span class="sd">            If False, the input will be checked for consistency with</span>
<span class="sd">            feature names of data provided when reset was last True.</span>
<span class="sd">            .. note::</span>
<span class="sd">               It is recommended to call `reset=True` in `fit` and in the first</span>
<span class="sd">               call to `partial_fit`. All other methods that validate `X`</span>
<span class="sd">               should set `reset=False`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">reset</span><span class="p">:</span>
            <span class="n">feature_names_in</span> <span class="o">=</span> <span class="n">_get_feature_names</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feature_names_in</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">feature_names_in_</span> <span class="o">=</span> <span class="n">feature_names_in</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;feature_names_in_&quot;</span><span class="p">):</span>
                <span class="c1"># Delete the attribute when the estimator is fitted on a new dataset</span>
                <span class="c1"># that has no feature names.</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;feature_names_in_&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">fitted_feature_names</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;feature_names_in_&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">X_feature_names</span> <span class="o">=</span> <span class="n">_get_feature_names</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fitted_feature_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">X_feature_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># no feature names seen in fit and in X</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">X_feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">fitted_feature_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;X has feature names, but </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> was fitted without&quot;</span>
                <span class="s2">&quot; feature names&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">X_feature_names</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">fitted_feature_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;X does not have valid feature names, but&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> was fitted with feature names&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># validate the feature names against the `feature_names_in_` attribute</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">fitted_feature_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_feature_names</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span>
            <span class="n">fitted_feature_names</span> <span class="o">!=</span> <span class="n">X_feature_names</span>
        <span class="p">):</span>
            <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;The feature names should match those that were passed during fit.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">fitted_feature_names_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">fitted_feature_names</span><span class="p">)</span>
            <span class="n">X_feature_names_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">X_feature_names</span><span class="p">)</span>

            <span class="n">unexpected_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">X_feature_names_set</span> <span class="o">-</span> <span class="n">fitted_feature_names_set</span><span class="p">)</span>
            <span class="n">missing_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">fitted_feature_names_set</span> <span class="o">-</span> <span class="n">X_feature_names_set</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">add_names</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
                <span class="n">output</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
                <span class="n">max_n_names</span> <span class="o">=</span> <span class="mi">5</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">max_n_names</span><span class="p">:</span>
                        <span class="n">output</span> <span class="o">+=</span> <span class="s2">&quot;- ...</span><span class="se">\n</span><span class="s2">&quot;</span>
                        <span class="k">break</span>
                    <span class="n">output</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;- </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="k">return</span> <span class="n">output</span>

            <span class="k">if</span> <span class="n">unexpected_names</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="s2">&quot;Feature names unseen at fit time:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="n">add_names</span><span class="p">(</span><span class="n">unexpected_names</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">missing_names</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="s2">&quot;Feature names seen at fit time, yet now missing:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="n">add_names</span><span class="p">(</span><span class="n">missing_names</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">missing_names</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">unexpected_names</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="s2">&quot;Feature names must be in the same order as they were in fit.</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="o">=</span><span class="s2">&quot;no_validation&quot;</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="s2">&quot;no_validation&quot;</span><span class="p">,</span>
        <span class="n">reset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">validate_separately</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">cast_to_ndarray</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">check_params</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate input data and set or check the `n_features_in_` attribute.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix, dataframe} of shape \</span>
<span class="sd">                (n_samples, n_features), default=&#39;no validation&#39;</span>
<span class="sd">            The input samples.</span>
<span class="sd">            If `&#39;no_validation&#39;`, no validation is performed on `X`. This is</span>
<span class="sd">            useful for meta-estimator which can delegate input validation to</span>
<span class="sd">            their underlying estimator(s). In that case `y` must be passed and</span>
<span class="sd">            the only accepted `check_params` are `multi_output` and</span>
<span class="sd">            `y_numeric`.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=&#39;no_validation&#39;</span>
<span class="sd">            The targets.</span>

<span class="sd">            - If `None`, `check_array` is called on `X`. If the estimator&#39;s</span>
<span class="sd">              requires_y tag is True, then an error will be raised.</span>
<span class="sd">            - If `&#39;no_validation&#39;`, `check_array` is called on `X` and the</span>
<span class="sd">              estimator&#39;s requires_y tag is ignored. This is a default</span>
<span class="sd">              placeholder and is never meant to be explicitly set. In that case</span>
<span class="sd">              `X` must be passed.</span>
<span class="sd">            - Otherwise, only `y` with `_check_y` or both `X` and `y` are</span>
<span class="sd">              checked with either `check_array` or `check_X_y` depending on</span>
<span class="sd">              `validate_separately`.</span>

<span class="sd">        reset : bool, default=True</span>
<span class="sd">            Whether to reset the `n_features_in_` attribute.</span>
<span class="sd">            If False, the input will be checked for consistency with data</span>
<span class="sd">            provided when reset was last True.</span>
<span class="sd">            .. note::</span>
<span class="sd">               It is recommended to call reset=True in `fit` and in the first</span>
<span class="sd">               call to `partial_fit`. All other methods that validate `X`</span>
<span class="sd">               should set `reset=False`.</span>

<span class="sd">        validate_separately : False or tuple of dicts, default=False</span>
<span class="sd">            Only used if y is not None.</span>
<span class="sd">            If False, call validate_X_y(). Else, it must be a tuple of kwargs</span>
<span class="sd">            to be used for calling check_array() on X and y respectively.</span>

<span class="sd">            `estimator=self` is automatically added to these dicts to generate</span>
<span class="sd">            more informative error message in case of invalid input data.</span>

<span class="sd">        cast_to_ndarray : bool, default=True</span>
<span class="sd">            Cast `X` and `y` to ndarray with checks in `check_params`. If</span>
<span class="sd">            `False`, `X` and `y` are unchanged and only `feature_names_in_` and</span>
<span class="sd">            `n_features_in_` are checked.</span>

<span class="sd">        **check_params : kwargs</span>
<span class="sd">            Parameters passed to :func:`sklearn.utils.check_array` or</span>
<span class="sd">            :func:`sklearn.utils.check_X_y`. Ignored if validate_separately</span>
<span class="sd">            is not False.</span>

<span class="sd">            `estimator=self` is automatically added to these params to generate</span>
<span class="sd">            more informative error message in case of invalid input data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : {ndarray, sparse matrix} or tuple of these</span>
<span class="sd">            The validated input. A tuple is returned if both `X` and `y` are</span>
<span class="sd">            validated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_feature_names</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="n">reset</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_tags</span><span class="p">()[</span><span class="s2">&quot;requires_y&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;This </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> estimator &quot;</span>
                <span class="s2">&quot;requires y to be passed, but the target y is None.&quot;</span>
            <span class="p">)</span>

        <span class="n">no_val_X</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">X</span> <span class="o">==</span> <span class="s2">&quot;no_validation&quot;</span>
        <span class="n">no_val_y</span> <span class="o">=</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">y</span> <span class="o">==</span> <span class="s2">&quot;no_validation&quot;</span>

        <span class="k">if</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">no_val_y</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Validation should be done on X, y or both.&quot;</span><span class="p">)</span>

        <span class="n">default_check_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="p">}</span>
        <span class="n">check_params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_check_params</span><span class="p">,</span> <span class="o">**</span><span class="n">check_params</span><span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">cast_to_ndarray</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">no_val_y</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">X</span>
            <span class="k">elif</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_val_y</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">y</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">no_val_y</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">check_params</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_val_y</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">_check_y</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">check_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">validate_separately</span><span class="p">:</span>
                <span class="c1"># We need this because some estimators validate X and y</span>
                <span class="c1"># separately, and in general, separately calling check_array()</span>
                <span class="c1"># on X and y isn&#39;t equivalent to just calling check_X_y()</span>
                <span class="c1"># :(</span>
                <span class="n">check_X_params</span><span class="p">,</span> <span class="n">check_y_params</span> <span class="o">=</span> <span class="n">validate_separately</span>
                <span class="k">if</span> <span class="s2">&quot;estimator&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">check_X_params</span><span class="p">:</span>
                    <span class="n">check_X_params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_check_params</span><span class="p">,</span> <span class="o">**</span><span class="n">check_X_params</span><span class="p">}</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">check_X_params</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;estimator&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">check_y_params</span><span class="p">:</span>
                    <span class="n">check_y_params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_check_params</span><span class="p">,</span> <span class="o">**</span><span class="n">check_y_params</span><span class="p">}</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">input_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">check_y_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">check_params</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">no_val_X</span> <span class="ow">and</span> <span class="n">check_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;ensure_2d&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_n_features</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">reset</span><span class="o">=</span><span class="n">reset</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">_validate_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Validate types and values of constructor parameters</span>

<span class="sd">        The expected type and values must be defined in the `_parameter_constraints`</span>
<span class="sd">        class attribute, which is a dictionary `param_name: list of constraints`. See</span>
<span class="sd">        the docstring of `validate_parameter_constraints` for a description of the</span>
<span class="sd">        accepted constraints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">validate_parameter_constraints</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">caller_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">_repr_html_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;HTML representation of estimator.</span>

<span class="sd">        This is redundant with the logic of `_repr_mimebundle_`. The latter</span>
<span class="sd">        should be favorted in the long term, `_repr_html_` is only</span>
<span class="sd">        implemented for consumers who do not interpret `_repr_mimbundle_`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;display&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;diagram&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="s2">&quot;_repr_html_ is only defined when the &quot;</span>
                <span class="s2">&quot;&#39;display&#39; configuration option is set to &quot;</span>
                <span class="s2">&quot;&#39;diagram&#39;&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repr_html_inner</span>

    <span class="k">def</span> <span class="nf">_repr_html_inner</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This function is returned by the @property `_repr_html_` to make</span>
<span class="sd">        `hasattr(estimator, &quot;_repr_html_&quot;) return `True` or `False` depending</span>
<span class="sd">        on `get_config()[&quot;display&quot;]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">estimator_html_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_repr_mimebundle_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mime bundle used by jupyter kernels to display estimator&quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;text/plain&quot;</span><span class="p">:</span> <span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)}</span>
        <span class="k">if</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;display&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;diagram&quot;</span><span class="p">:</span>
            <span class="n">output</span><span class="p">[</span><span class="s2">&quot;text/html&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">estimator_html_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">ClassifierMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all classifiers in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - `_estimator_type` class attribute defaulting to `&quot;classifier&quot;`;</span>
<span class="sd">    - `score` method that default to :func:`~sklearn.metrics.accuracy_score`.</span>
<span class="sd">    - enforce that `fit` requires `y` to be passed through the `requires_y` tag.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, ClassifierMixin</span>
<span class="sd">    &gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(ClassifierMixin, BaseEstimator):</span>
<span class="sd">    ...     def __init__(self, *, param=1):</span>
<span class="sd">    ...         self.param = param</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.is_fitted_ = True</span>
<span class="sd">    ...         return self</span>
<span class="sd">    ...     def predict(self, X):</span>
<span class="sd">    ...         return np.full(shape=X.shape[0], fill_value=self.param)</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator(param=1)</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 0, 1])</span>
<span class="sd">    &gt;&gt;&gt; estimator.fit(X, y).predict(X)</span>
<span class="sd">    array([1, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; estimator.score(X, y)</span>
<span class="sd">    0.66...</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;classifier&quot;</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return the mean accuracy on the given test data and labels.</span>

<span class="sd">        In multi-label classification, this is the subset accuracy</span>
<span class="sd">        which is a harsh metric since you require for each sample that</span>
<span class="sd">        each label set be correctly predicted.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Test samples.</span>

<span class="sd">        y : array-like of shape (n_samples,) or (n_samples, n_outputs)</span>
<span class="sd">            True labels for `X`.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Sample weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

        <span class="k">return</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;requires_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">RegressorMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all regression estimators in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - `_estimator_type` class attribute defaulting to `&quot;regressor&quot;`;</span>
<span class="sd">    - `score` method that default to :func:`~sklearn.metrics.r2_score`.</span>
<span class="sd">    - enforce that `fit` requires `y` to be passed through the `requires_y` tag.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;rolling_your_own_estimator&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, RegressorMixin</span>
<span class="sd">    &gt;&gt;&gt; # Mixin classes should always be on the left-hand side for a correct MRO</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(RegressorMixin, BaseEstimator):</span>
<span class="sd">    ...     def __init__(self, *, param=1):</span>
<span class="sd">    ...         self.param = param</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.is_fitted_ = True</span>
<span class="sd">    ...         return self</span>
<span class="sd">    ...     def predict(self, X):</span>
<span class="sd">    ...         return np.full(shape=X.shape[0], fill_value=self.param)</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator(param=0)</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([-1, 0, 1])</span>
<span class="sd">    &gt;&gt;&gt; estimator.fit(X, y).predict(X)</span>
<span class="sd">    array([0, 0, 0])</span>
<span class="sd">    &gt;&gt;&gt; estimator.score(X, y)</span>
<span class="sd">    0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;regressor&quot;</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the coefficient of determination of the prediction.</span>

<span class="sd">        The coefficient of determination :math:`R^2` is defined as</span>
<span class="sd">        :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual</span>
<span class="sd">        sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`</span>
<span class="sd">        is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.</span>
<span class="sd">        The best possible score is 1.0 and it can be negative (because the</span>
<span class="sd">        model can be arbitrarily worse). A constant model that always predicts</span>
<span class="sd">        the expected value of `y`, disregarding the input features, would get</span>
<span class="sd">        a :math:`R^2` score of 0.0.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Test samples. For some estimators this may be a precomputed</span>
<span class="sd">            kernel matrix or a list of generic objects instead with shape</span>
<span class="sd">            ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``</span>
<span class="sd">            is the number of samples used in the fitting for the estimator.</span>

<span class="sd">        y : array-like of shape (n_samples,) or (n_samples, n_outputs)</span>
<span class="sd">            True values for `X`.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Sample weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">            :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        The :math:`R^2` score used when calling ``score`` on a regressor uses</span>
<span class="sd">        ``multioutput=&#39;uniform_average&#39;`` from version 0.23 to keep consistent</span>
<span class="sd">        with default value of :func:`~sklearn.metrics.r2_score`.</span>
<span class="sd">        This influences the ``score`` method of all the multioutput</span>
<span class="sd">        regressors (except for</span>
<span class="sd">        :class:`~sklearn.multioutput.MultiOutputRegressor`).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;requires_y&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">ClusterMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all cluster estimators in scikit-learn.</span>

<span class="sd">    - `_estimator_type` class attribute defaulting to `&quot;clusterer&quot;`;</span>
<span class="sd">    - `fit_predict` method returning the cluster labels associated to each sample.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, ClusterMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyClusterer(ClusterMixin, BaseEstimator):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.labels_ = np.ones(shape=(len(X),), dtype=np.int64)</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; X = [[1, 2], [2, 3], [3, 4]]</span>
<span class="sd">    &gt;&gt;&gt; MyClusterer().fit_predict(X)</span>
<span class="sd">    array([1, 1, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;clusterer&quot;</span>

    <span class="k">def</span> <span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform clustering on `X` and returns cluster labels.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Input data.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present for API consistency by convention.</span>

<span class="sd">        **kwargs : dict</span>
<span class="sd">            Arguments to be passed to ``fit``.</span>

<span class="sd">            .. versionadded:: 1.4</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        labels : ndarray of shape (n_samples,), dtype=np.int64</span>
<span class="sd">            Cluster labels.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># non-optimized default implementation; override when a better</span>
        <span class="c1"># method is possible for a given clustering algorithm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;preserves_dtype&quot;</span><span class="p">:</span> <span class="p">[]}</span>


<span class="k">class</span> <span class="nc">BiclusterMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all bicluster estimators in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - `biclusters_` property that returns the row and column indicators;</span>
<span class="sd">    - `get_indices` method that returns the row and column indices of a bicluster;</span>
<span class="sd">    - `get_shape` method that returns the shape of a bicluster;</span>
<span class="sd">    - `get_submatrix` method that returns the submatrix corresponding to a bicluster.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, BiclusterMixin</span>
<span class="sd">    &gt;&gt;&gt; class DummyBiClustering(BiclusterMixin, BaseEstimator):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.rows_ = np.ones(shape=(1, X.shape[0]), dtype=bool)</span>
<span class="sd">    ...         self.columns_ = np.ones(shape=(1, X.shape[1]), dtype=bool)</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 1], [2, 1], [1, 0],</span>
<span class="sd">    ...               [4, 7], [3, 5], [3, 6]])</span>
<span class="sd">    &gt;&gt;&gt; bicluster = DummyBiClustering().fit(X)</span>
<span class="sd">    &gt;&gt;&gt; hasattr(bicluster, &quot;biclusters_&quot;)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; bicluster.get_indices(0)</span>
<span class="sd">    (array([0, 1, 2, 3, 4, 5]), array([0, 1]))</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">biclusters_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convenient way to get row and column indicators together.</span>

<span class="sd">        Returns the ``rows_`` and ``columns_`` members.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">columns_</span>

    <span class="k">def</span> <span class="nf">get_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Row and column indices of the `i`&#39;th bicluster.</span>

<span class="sd">        Only works if ``rows_`` and ``columns_`` attributes exist.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i : int</span>
<span class="sd">            The index of the cluster.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        row_ind : ndarray, dtype=np.intp</span>
<span class="sd">            Indices of rows in the dataset that belong to the bicluster.</span>
<span class="sd">        col_ind : ndarray, dtype=np.intp</span>
<span class="sd">            Indices of columns in the dataset that belong to the bicluster.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rows_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">columns_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">rows</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">columns</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shape of the `i`&#39;th bicluster.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i : int</span>
<span class="sd">            The index of the cluster.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_rows : int</span>
<span class="sd">            Number of rows in the bicluster.</span>

<span class="sd">        n_cols : int</span>
<span class="sd">            Number of columns in the bicluster.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_indices</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_submatrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the submatrix corresponding to bicluster `i`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        i : int</span>
<span class="sd">            The index of the cluster.</span>
<span class="sd">        data : array-like of shape (n_samples, n_features)</span>
<span class="sd">            The data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        submatrix : ndarray of shape (n_rows, n_cols)</span>
<span class="sd">            The submatrix corresponding to bicluster `i`.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Works with sparse matrices. Only works if ``rows_`` and</span>
<span class="sd">        ``columns_`` attributes exist.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">.utils.validation</span> <span class="kn">import</span> <span class="n">check_array</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
        <span class="n">row_ind</span><span class="p">,</span> <span class="n">col_ind</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_indices</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="n">row_ind</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">col_ind</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">TransformerMixin</span><span class="p">(</span><span class="n">_SetOutputMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all transformers in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - a `fit_transform` method that delegates to `fit` and `transform`;</span>
<span class="sd">    - a `set_output` method to output `X` as a specific container type.</span>

<span class="sd">    If :term:`get_feature_names_out` is defined, then :class:`BaseEstimator` will</span>
<span class="sd">    automatically wrap `transform` and `fit_transform` to follow the `set_output`</span>
<span class="sd">    API. See the :ref:`developer_api_set_output` for details.</span>

<span class="sd">    :class:`OneToOneFeatureMixin` and</span>
<span class="sd">    :class:`ClassNamePrefixFeaturesOutMixin` are helpful mixins for</span>
<span class="sd">    defining :term:`get_feature_names_out`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, TransformerMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyTransformer(TransformerMixin, BaseEstimator):</span>
<span class="sd">    ...     def __init__(self, *, param=1):</span>
<span class="sd">    ...         self.param = param</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         return self</span>
<span class="sd">    ...     def transform(self, X):</span>
<span class="sd">    ...         return np.full(shape=len(X), fill_value=self.param)</span>
<span class="sd">    &gt;&gt;&gt; transformer = MyTransformer()</span>
<span class="sd">    &gt;&gt;&gt; X = [[1, 2], [2, 3], [3, 4]]</span>
<span class="sd">    &gt;&gt;&gt; transformer.fit_transform(X)</span>
<span class="sd">    array([1, 1, 1])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit to data, then transform it.</span>

<span class="sd">        Fits transformer to `X` and `y` with optional parameters `fit_params`</span>
<span class="sd">        and returns a transformed version of `X`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Input samples.</span>

<span class="sd">        y :  array-like of shape (n_samples,) or (n_samples, n_outputs), \</span>
<span class="sd">                default=None</span>
<span class="sd">            Target values (None for unsupervised transformations).</span>

<span class="sd">        **fit_params : dict</span>
<span class="sd">            Additional fit parameters.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        X_new : ndarray array of shape (n_samples, n_features_new)</span>
<span class="sd">            Transformed array.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># non-optimized default implementation; override when a better</span>
        <span class="c1"># method is possible for a given clustering algorithm</span>

        <span class="c1"># we do not route parameters here, since consumers don&#39;t route. But</span>
        <span class="c1"># since it&#39;s possible for a `transform` method to also consume</span>
        <span class="c1"># metadata, we check if that&#39;s the case, and we raise a warning telling</span>
        <span class="c1"># users that they should implement a custom `fit_transform` method</span>
        <span class="c1"># to forward metadata to `transform` as well.</span>
        <span class="c1">#</span>
        <span class="c1"># For that, we calculate routing and check if anything would be routed</span>
        <span class="c1"># to `transform` if we were to route them.</span>
        <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
            <span class="n">transform_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_metadata_routing</span><span class="p">()</span><span class="o">.</span><span class="n">consumes</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;transform&quot;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">fit_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">transform_params</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;This object (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) has a `transform`&quot;</span>
                        <span class="s2">&quot; method which consumes metadata, but `fit_transform` does not&quot;</span>
                        <span class="s2">&quot; forward metadata to `transform`. Please implement a custom&quot;</span>
                        <span class="s2">&quot; `fit_transform` method to forward metadata to `transform` as&quot;</span>
                        <span class="s2">&quot; well. Alternatively, you can explicitly do&quot;</span>
                        <span class="s2">&quot; `set_transform_request`and set all values to `False` to&quot;</span>
                        <span class="s2">&quot; disable metadata routed to `transform`, if that&#39;s an option.&quot;</span>
                    <span class="p">),</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># fit method of arity 1 (unsupervised transformation)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># fit method of arity 2 (supervised transformation)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">fit_params</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OneToOneFeatureMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Provides `get_feature_names_out` for simple transformers.</span>

<span class="sd">    This mixin assumes there&#39;s a 1-to-1 correspondence between input features</span>
<span class="sd">    and output features, such as :class:`~sklearn.preprocessing.StandardScaler`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import OneToOneFeatureMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(OneToOneFeatureMixin):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.n_features_in_ = X.shape[1]</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; MyEstimator().fit(X).get_feature_names_out()</span>
<span class="sd">    array([&#39;x0&#39;, &#39;x1&#39;], dtype=object)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_feature_names_out</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get output feature names for transformation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_features : array-like of str or None, default=None</span>
<span class="sd">            Input features.</span>

<span class="sd">            - If `input_features` is `None`, then `feature_names_in_` is</span>
<span class="sd">              used as feature names in. If `feature_names_in_` is not defined,</span>
<span class="sd">              then the following input feature names are generated:</span>
<span class="sd">              `[&quot;x0&quot;, &quot;x1&quot;, ..., &quot;x(n_features_in_ - 1)&quot;]`.</span>
<span class="sd">            - If `input_features` is an array-like, then `input_features` must</span>
<span class="sd">              match `feature_names_in_` if `feature_names_in_` is defined.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        feature_names_out : ndarray of str objects</span>
<span class="sd">            Same as input features.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;n_features_in_&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_check_feature_names_in</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ClassNamePrefixFeaturesOutMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for transformers that generate their own names by prefixing.</span>

<span class="sd">    This mixin is useful when the transformer needs to generate its own feature</span>
<span class="sd">    names out, such as :class:`~sklearn.decomposition.PCA`. For example, if</span>
<span class="sd">    :class:`~sklearn.decomposition.PCA` outputs 3 features, then the generated feature</span>
<span class="sd">    names out are: `[&quot;pca0&quot;, &quot;pca1&quot;, &quot;pca2&quot;]`.</span>

<span class="sd">    This mixin assumes that a `_n_features_out` attribute is defined when the</span>
<span class="sd">    transformer is fitted. `_n_features_out` is the number of output features</span>
<span class="sd">    that the transformer will return in `transform` of `fit_transform`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import ClassNamePrefixFeaturesOutMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(ClassNamePrefixFeaturesOutMixin):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self._n_features_out = X.shape[1]</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; MyEstimator().fit(X).get_feature_names_out()</span>
<span class="sd">    array([&#39;myestimator0&#39;, &#39;myestimator1&#39;], dtype=object)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_feature_names_out</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get output feature names for transformation.</span>

<span class="sd">        The feature names out will prefixed by the lowercased class name. For</span>
<span class="sd">        example, if the transformer outputs 3 features, then the feature names</span>
<span class="sd">        out are: `[&quot;class_name0&quot;, &quot;class_name1&quot;, &quot;class_name2&quot;]`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_features : array-like of str or None, default=None</span>
<span class="sd">            Only used to validate feature names with the names seen in `fit`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        feature_names_out : ndarray of str objects</span>
<span class="sd">            Transformed feature names.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_n_features_out&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_generate_get_feature_names_out</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_features_out</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">input_features</span>
        <span class="p">)</span>


<span class="k">class</span> <span class="nc">DensityMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all density estimators in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - `_estimator_type` class attribute defaulting to `&quot;DensityEstimator&quot;`;</span>
<span class="sd">    - `score` method that default that do no-op.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import DensityMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(DensityMixin):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.is_fitted_ = True</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator()</span>
<span class="sd">    &gt;&gt;&gt; hasattr(estimator, &quot;score&quot;)</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;DensityEstimator&quot;</span>

    <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the score of the model on the data `X`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Test samples.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present for API consistency by convention.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        score : float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>


<span class="k">class</span> <span class="nc">OutlierMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all outlier detection estimators in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - `_estimator_type` class attribute defaulting to `outlier_detector`;</span>
<span class="sd">    - `fit_predict` method that default to `fit` and `predict`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import BaseEstimator, OutlierMixin</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(OutlierMixin):</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         self.is_fitted_ = True</span>
<span class="sd">    ...         return self</span>
<span class="sd">    ...     def predict(self, X):</span>
<span class="sd">    ...         return np.ones(shape=len(X))</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator()</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [2, 3], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; estimator.fit_predict(X)</span>
<span class="sd">    array([1., 1., 1.])</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_estimator_type</span> <span class="o">=</span> <span class="s2">&quot;outlier_detector&quot;</span>

    <span class="k">def</span> <span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform fit on X and returns labels for X.</span>

<span class="sd">        Returns -1 for outliers and 1 for inliers.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            The input samples.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present for API consistency by convention.</span>

<span class="sd">        **kwargs : dict</span>
<span class="sd">            Arguments to be passed to ``fit``.</span>

<span class="sd">            .. versionadded:: 1.4</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y : ndarray of shape (n_samples,)</span>
<span class="sd">            1 for inliers, -1 for outliers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># we do not route parameters here, since consumers don&#39;t route. But</span>
        <span class="c1"># since it&#39;s possible for a `predict` method to also consume</span>
        <span class="c1"># metadata, we check if that&#39;s the case, and we raise a warning telling</span>
        <span class="c1"># users that they should implement a custom `fit_predict` method</span>
        <span class="c1"># to forward metadata to `predict` as well.</span>
        <span class="c1">#</span>
        <span class="c1"># For that, we calculate routing and check if anything would be routed</span>
        <span class="c1"># to `predict` if we were to route them.</span>
        <span class="k">if</span> <span class="n">_routing_enabled</span><span class="p">():</span>
            <span class="n">transform_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_metadata_routing</span><span class="p">()</span><span class="o">.</span><span class="n">consumes</span><span class="p">(</span>
                <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">transform_params</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;This object (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">) has a `predict` &quot;</span>
                        <span class="s2">&quot;method which consumes metadata, but `fit_predict` does not &quot;</span>
                        <span class="s2">&quot;forward metadata to `predict`. Please implement a custom &quot;</span>
                        <span class="s2">&quot;`fit_predict` method to forward metadata to `predict` as well.&quot;</span>
                        <span class="s2">&quot;Alternatively, you can explicitly do `set_predict_request`&quot;</span>
                        <span class="s2">&quot;and set all values to `False` to disable metadata routed to &quot;</span>
                        <span class="s2">&quot;`predict`, if that&#39;s an option.&quot;</span>
                    <span class="p">),</span>
                    <span class="ne">UserWarning</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># override for transductive outlier detectors like LocalOulierFactor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MetaEstimatorMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin class for all meta estimators in scikit-learn.</span>

<span class="sd">    This mixin defines the following functionality:</span>

<span class="sd">    - define `_required_parameters` that specify the mandatory `estimator` parameter.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import MetaEstimatorMixin</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; class MyEstimator(MetaEstimatorMixin):</span>
<span class="sd">    ...     def __init__(self, *, estimator=None):</span>
<span class="sd">    ...         self.estimator = estimator</span>
<span class="sd">    ...     def fit(self, X, y=None):</span>
<span class="sd">    ...         if self.estimator is None:</span>
<span class="sd">    ...             self.estimator_ = LogisticRegression()</span>
<span class="sd">    ...         else:</span>
<span class="sd">    ...             self.estimator_ = self.estimator</span>
<span class="sd">    ...         return self</span>
<span class="sd">    &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span>
<span class="sd">    &gt;&gt;&gt; estimator = MyEstimator().fit(X, y)</span>
<span class="sd">    &gt;&gt;&gt; estimator.estimator_</span>
<span class="sd">    LogisticRegression()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_required_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;estimator&quot;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">MultiOutputMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mixin to mark estimators that support multioutput.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;multioutput&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">_UnstableArchMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mark estimators that are non-determinstic on 32bit or PowerPC&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_more_tags</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;non_deterministic&quot;</span><span class="p">:</span> <span class="n">_IS_32BIT</span> <span class="ow">or</span> <span class="n">platform</span><span class="o">.</span><span class="n">machine</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;ppc&quot;</span><span class="p">,</span> <span class="s2">&quot;powerpc&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">}</span>


<span class="k">def</span> <span class="nf">is_classifier</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return True if the given estimator is (probably) a classifier.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : object</span>
<span class="sd">        Estimator object to test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out : bool</span>
<span class="sd">        True if estimator is a classifier and False otherwise.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import is_classifier</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import SVC, SVR</span>
<span class="sd">    &gt;&gt;&gt; classifier = SVC()</span>
<span class="sd">    &gt;&gt;&gt; regressor = SVR()</span>
<span class="sd">    &gt;&gt;&gt; is_classifier(classifier)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; is_classifier(regressor)</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_estimator_type&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;classifier&quot;</span>


<span class="k">def</span> <span class="nf">is_regressor</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return True if the given estimator is (probably) a regressor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator instance</span>
<span class="sd">        Estimator object to test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out : bool</span>
<span class="sd">        True if estimator is a regressor and False otherwise.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.base import is_regressor</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import SVC, SVR</span>
<span class="sd">    &gt;&gt;&gt; classifier = SVC()</span>
<span class="sd">    &gt;&gt;&gt; regressor = SVR()</span>
<span class="sd">    &gt;&gt;&gt; is_regressor(classifier)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; is_regressor(regressor)</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_estimator_type&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;regressor&quot;</span>


<span class="k">def</span> <span class="nf">is_outlier_detector</span><span class="p">(</span><span class="n">estimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return True if the given estimator is (probably) an outlier detector.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimator : estimator instance</span>
<span class="sd">        Estimator object to test.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    out : bool</span>
<span class="sd">        True if estimator is an outlier detector and False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;_estimator_type&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;outlier_detector&quot;</span>


<span class="k">def</span> <span class="nf">_fit_context</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">prefer_skip_nested_validation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decorator to run the fit methods of estimators within context managers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    prefer_skip_nested_validation : bool</span>
<span class="sd">        If True, the validation of parameters of inner estimators or functions</span>
<span class="sd">        called during fit will be skipped.</span>

<span class="sd">        This is useful to avoid validating many times the parameters passed by the</span>
<span class="sd">        user from the public facing API. It&#39;s also useful to avoid validating</span>
<span class="sd">        parameters that we pass internally to inner functions that are guaranteed to</span>
<span class="sd">        be valid by the test suite.</span>

<span class="sd">        It should be set to True for most estimators, except for those that receive</span>
<span class="sd">        non-validated objects as parameters, such as meta-estimators that are given</span>
<span class="sd">        estimator objects.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    decorated_fit : method</span>
<span class="sd">        The decorated fit method.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">fit_method</span><span class="p">):</span>
        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">fit_method</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">global_skip_validation</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()[</span><span class="s2">&quot;skip_parameter_validation&quot;</span><span class="p">]</span>

            <span class="c1"># we don&#39;t want to validate again for each call to partial_fit</span>
            <span class="n">partial_fit_and_fitted</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">fit_method</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;partial_fit&quot;</span> <span class="ow">and</span> <span class="n">_is_fitted</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">global_skip_validation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">partial_fit_and_fitted</span><span class="p">:</span>
                <span class="n">estimator</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>

            <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span>
                <span class="n">skip_parameter_validation</span><span class="o">=</span><span class="p">(</span>
                    <span class="n">prefer_skip_nested_validation</span> <span class="ow">or</span> <span class="n">global_skip_validation</span>
                <span class="p">)</span>
            <span class="p">):</span>
                <span class="k">return</span> <span class="n">fit_method</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapper</span>

    <span class="k">return</span> <span class="n">decorator</span>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021, Chris Santiago
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../_static/documentation_options.js?v=01f34227"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/furo.js?v=32e29ea5"></script>
    </body>
</html>